{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untappd Scraper\n",
    "\n",
    "Due to the unique requirements of scraping untappd, selenium (headless or otherwise) is our best choice.  \n",
    "\n",
    "    1) Login required\n",
    "    2) Must select 'Show More' to see more than a handful of both search results and reviews\n",
    "    3) Odd design that is surprisingly difficult to use requests with\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config info\n",
    "\n",
    "Username, Password, and selenium driver path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'untappd.cfg'\n",
    "\n",
    "with open(config_path) as rdr:\n",
    "    config = json.load(rdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGIN_URL = 'https://untappd.com/login'\n",
    "CHUNK_SIZE = 25 ## URLs to scraper per session.  \n",
    "\n",
    "search_pkl = 'ipa_urls.pkl' ## Only perform search once.  It is picked otherwise.  If this file exists, search will not be performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log in\n",
    "\n",
    "    1) Create Browser Object\n",
    "    2) Find login elements\n",
    "    3) Fill them out, submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(config['driver_path'])\n",
    "browser.get(LOGIN_URL)\n",
    "\n",
    "username = browser.find_element_by_id(\"username\")\n",
    "password = browser.find_element_by_id(\"password\")\n",
    "\n",
    "username.send_keys(config['username'])\n",
    "password.send_keys(config['password'])\n",
    "\n",
    "browser.find_element_by_xpath(\"//input[@type='submit']\").click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "\n",
    "Sometimes along the bottom, a prompt to download the app appears.  It's hard to identify and click for some reason with selenium.  Closing it once per session will keep it closed.  Go ahead and look for that now, before continuing.  If it's there, just click 'x'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify IPA URLS\n",
    "\n",
    "If the pickle file exists, load it.  Otherwise, perform search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beers_from_search(search_term, browser):\n",
    "    ## Create search URL and go\n",
    "    browser.get('https://untappd.com/search?q={}'.format(search_term.strip().replace(' ', '+')))\n",
    "    \n",
    "    ## Click the show more button\n",
    "    for i in range(25):\n",
    "        try:\n",
    "            browser.find_element_by_xpath(\"//*[contains(text(), 'Show More')]\").click()\n",
    "            time.sleep(2)\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        except:\n",
    "            print('Error clicking \"Show More\" on iteration', i)\n",
    "            time.sleep(5)\n",
    "    \n",
    "    ## Find beer links on page\n",
    "    results = browser.find_elements_by_css_selector('.beer-item')\n",
    "    \n",
    "    urls = []\n",
    "    for result in results:\n",
    "        for url in result.find_elements_by_tag_name('a'):\n",
    "            if url.get_attribute('href').startswith(r'https://untappd.com/beer'):\n",
    "                urls.append(url.get_attribute('href'))\n",
    "\n",
    "    print(len(urls), 'beers found for search', search_term)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def write_pkl(filename, data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def read_pkl(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pickled URLS\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(search_pkl): \n",
    "    print('Pickle file not found.  Performing search.')\n",
    "    \n",
    "    beer_urls = set()\n",
    "\n",
    "    search_terms = ['ipa', 'dipa', 'double ipa', 'hazy ipa']\n",
    "\n",
    "    for search_term in search_terms:\n",
    "        urls = set(get_beers_from_search(search_term, browser))\n",
    "        beer_urls = beer_urls.union(urls)\n",
    "\n",
    "        print('total url count:', len(beer_urls))\n",
    "    \n",
    "    ## Write out our pickle file\n",
    "    write_pkl('ipa_urls.pkl', beer_urls)\n",
    "    \n",
    "else:\n",
    "    ## Read pickled data\n",
    "    print(\"Reading pickled URLS\")\n",
    "    beer_urls = read_pkl('ipa_urls.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Function for identifying/naming files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_naming_funct(file_format):\n",
    "    \"\"\"file_format is intended to come in as folder/filename_{}.extension, where the {} will be replaced by a number (0000, 00001, etc)\"\"\"\n",
    "    file_format = file_format\n",
    "    \n",
    "    def identify_checkpoint():\n",
    "        nonlocal file_format\n",
    "        existing_files = glob.glob(file_format.format('*'))\n",
    "        return len(existing_files), file_format.format(str(len(existing_files)).zfill(5)) \n",
    "    \n",
    "    return identify_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_checkpointer = create_naming_funct('data/beer_info_{}.json')\n",
    "review_checkpointer = create_naming_funct('data/reviews_{}.json')\n",
    "user_checkpointer = create_naming_funct('data/users_{}.json')\n",
    "\n",
    "url_checkpointer = create_naming_funct('checkpoints/run_checkpoint_{}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we have a set of URLS to iterate over, we can begin scraping reviews.  \n",
    "\n",
    "We'll have to load each page, push the show more button a bunch, and scrape the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beer_info(browser, url):\n",
    "    classnames = 'name,brewery,style,abv,ibu,rating,raters,date'.split(',')\n",
    "    \n",
    "    browser.get(url)\n",
    "    \n",
    "    beer_id = url.split('/')[-1]\n",
    "\n",
    "    ## Populate the beer info\n",
    "    beer_info = {}\n",
    "    beer_info['id'] = beer_id\n",
    "    \n",
    "    try:\n",
    "        element = browser.find_element_by_class_name('beer-descrption-read-more')\n",
    "        if not element:\n",
    "            print('didnt find element.  pausing')\n",
    "            time.sleep(10)\n",
    "    except:\n",
    "        print('Exception caught. pausing')\n",
    "        time.sleep(10)\n",
    "\n",
    "    ## If there is no \"Show More\" button, catch that error\n",
    "    try:\n",
    "        browser.find_element_by_class_name('beer-descrption-read-more').find_element_by_link_text('Show More').click()\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    beer_info['description'] = browser.find_element_by_class_name('beer-descrption-read-less').text[:-10]\n",
    "\n",
    "    for classname in classnames:\n",
    "        beer_info[classname] =  browser.find_element_by_class_name(classname).text\n",
    "        if classname == 'name':\n",
    "            beer_info[classname] = browser.find_element_by_class_name(classname).find_element_by_tag_name('h1').text\n",
    "\n",
    "    \n",
    "    return beer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(browser, beer_id):\n",
    "    ## Show more reviews!\n",
    "    ## Click the show more button\n",
    "    fail_count = 0\n",
    "    \n",
    "    for i in range(50):\n",
    "        try:\n",
    "            browser.find_elements_by_xpath(\"//*[contains(text(), 'Show More')]\")[1].click()\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except:\n",
    "            fail_count += 1\n",
    "            if fail_count > 2:\n",
    "                break\n",
    "            time.sleep(4)\n",
    "            \n",
    "    \n",
    "    ## Get reviews\n",
    "    user_reviews = []\n",
    "    \n",
    "    user_reviews_elems = browser.find_element_by_id('main-stream').find_elements_by_class_name('checkin')\n",
    "    for user_review_elem in user_reviews_elems:\n",
    "        rating_dict = {}\n",
    "        rating_dict['beer_id'] = beer_id\n",
    "        rating_dict['user_id'] = user_review_elem.find_element_by_class_name('user').get_attribute('href')\n",
    "\n",
    "        try:\n",
    "            rating = None\n",
    "            rating_spans = user_review_elem.find_element_by_class_name('rating-serving').find_elements_by_tag_name('span')\n",
    "            for span in rating_spans:\n",
    "                if span.get_attribute('class').startswith('rating small'):\n",
    "                    rating = span.get_attribute('class').split(' ')[-1][1:]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        rating_dict['comment'] = None\n",
    "        try:\n",
    "            rating_dict['comment'] = user_review_elem.find_element_by_class_name('comment-text').text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if rating:\n",
    "            if len(rating) > 1:\n",
    "                rating = rating[0] + '.' + rating[1:]\n",
    "            rating = float(rating)\n",
    "\n",
    "        rating_dict['rating'] = rating\n",
    "\n",
    "        user_reviews.append(rating_dict)\n",
    "        \n",
    "    return user_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading checkpoint file checkpoints/run_checkpoint_00026.pkl\n"
     ]
    }
   ],
   "source": [
    "## Identify checkpoints\n",
    "if url_checkpointer()[0] == 0:\n",
    "    print(\"Creating first checkpoint\")\n",
    "    \n",
    "    url_list = list(beer_urls)\n",
    "    write_pkl(url_checkpointer()[1], url_list)\n",
    "else:\n",
    "    \n",
    "    next_checkpoint = url_checkpointer()\n",
    "    \n",
    "    previous_checkpoint = next_checkpoint[1].replace(str(next_checkpoint[0]).zfill(5), str(next_checkpoint[0]-1).zfill(5))\n",
    "    print('Reading checkpoint file', previous_checkpoint)\n",
    "    url_list = read_pkl(previous_checkpoint)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: https://untappd.com/beer/2943312 Reviews found: 15 1889 Total Review Count: 15\n",
      "1: https://untappd.com/beer/2783468 Reviews found: 15 1704 Total Review Count: 30\n",
      "2: https://untappd.com/beer/2710568 Reviews found: 15 1965 Total Review Count: 45\n",
      "3: https://untappd.com/beer/1016833 Reviews found: 277 31364 Total Review Count: 322\n",
      "4: https://untappd.com/beer/2461404 Reviews found: 15 1780 Total Review Count: 337\n",
      "5: https://untappd.com/beer/2476735 Reviews found: 256 31228 Total Review Count: 593\n",
      "6: https://untappd.com/beer/2146934 Reviews found: 279 31894 Total Review Count: 872\n",
      "7: https://untappd.com/beer/2075737 Reviews found: 14 1482 Total Review Count: 886\n",
      "8: https://untappd.com/beer/43833 Reviews found: 281 30579 Total Review Count: 1167\n",
      "9: https://untappd.com/beer/215645 Reviews found: 237 27897 Total Review Count: 1404\n",
      "10: https://untappd.com/beer/2089569 Reviews found: 15 1825 Total Review Count: 1419\n",
      "11: https://untappd.com/beer/2526177 Reviews found: 274 30939 Total Review Count: 1693\n",
      "12: https://untappd.com/beer/603235 Reviews found: 273 30069 Total Review Count: 1966\n",
      "13: https://untappd.com/beer/2163117 Reviews found: 278 31483 Total Review Count: 2244\n",
      "14: https://untappd.com/beer/2823215 Reviews found: 197 23288 Total Review Count: 2441\n",
      "15: https://untappd.com/beer/740299 Reviews found: 279 31660 Total Review Count: 2720\n",
      "16: https://untappd.com/beer/2723792 Reviews found: 276 32938 Total Review Count: 2996\n",
      "17: https://untappd.com/beer/1714422 Reviews found: 15 1665 Total Review Count: 3011\n",
      "18: https://untappd.com/beer/2475870 Reviews found: 273 31003 Total Review Count: 3284\n",
      "19: https://untappd.com/beer/2599309 Reviews found: 13 1412 Total Review Count: 3297\n",
      "20: https://untappd.com/beer/660198 Reviews found: 273 30599 Total Review Count: 3570\n",
      "21: https://untappd.com/beer/2351428 Reviews found: 84 9405 Total Review Count: 3654\n",
      "22: https://untappd.com/beer/339609 Reviews found: 275 32712 Total Review Count: 3929\n",
      "23: https://untappd.com/beer/1353624 Reviews found: 275 33890 Total Review Count: 4204\n",
      "24: https://untappd.com/beer/989670 Reviews found: 227 25761 Total Review Count: 4431\n",
      "Run 0 took 1472.6986162662506 seconds. pausing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x in range(1):\n",
    "    \n",
    "    reviews = []\n",
    "    beers = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(CHUNK_SIZE):\n",
    "        url = url_list.pop()\n",
    "        print(str(i) + ':', url, end=' ')\n",
    "\n",
    "        beer_info = get_beer_info(browser, url)\n",
    "        beer_reviews = scrape_reviews(browser, beer_info['id'])\n",
    "\n",
    "        reviews.extend(beer_reviews)\n",
    "        beers.append(beer_info)\n",
    "\n",
    "        time.sleep(20)\n",
    "        print('Reviews found:', len(beer_reviews), len(json.dumps(beer_reviews)), 'Total Review Count:', len(reviews))\n",
    "\n",
    "    with open(beer_checkpointer()[1], 'w') as wtr:\n",
    "        json.dump(beers, wtr)\n",
    "\n",
    "    with open(review_checkpointer()[1], 'w') as wtr:\n",
    "        json.dump(reviews, wtr)\n",
    "\n",
    "    write_pkl(url_checkpointer()[1], url_list)\n",
    "    \n",
    "    print('Run', x, 'took', time.time()-start, 'seconds. pausing.')\n",
    "    time.sleep(240) # 1 minute pause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get user information!\n",
    "\n",
    "Identify all user urls, and figure out what information we can scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_urls = set([review['user_id'] for review in reviews])\n",
    "len(user_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = []\n",
    "for user_url in list(user_urls)[:100]:\n",
    "    \n",
    "    \n",
    "    browser.get(user_url)\n",
    "    \n",
    "    user_info = browser.find_element_by_class_name('user-info')\n",
    "\n",
    "    user_dict = {}\n",
    "    user_dict['name'] = user_info.find_element_by_class_name('info').find_element_by_tag_name('h1').text\n",
    "\n",
    "    user_dict['username'] = user_info.find_element_by_class_name('username').text\n",
    "    user_dict['location'] = user_info.find_element_by_class_name('username').text\n",
    "    user_dict['location'] = None if len(user_dict['location']) == 0 else user_dict['location']\n",
    "    user_dict['social'] = {}\n",
    "    social_list = user_info.find_element_by_class_name('social').find_elements_by_tag_name('a')\n",
    "    for social in social_list:\n",
    "        user_dict['social'][social.text] = social.get_attribute('href')\n",
    "\n",
    "\n",
    "    user_dict['stats'] = {}\n",
    "    stats_list = user_info.find_element_by_class_name('stats').find_elements_by_tag_name('a')\n",
    "    for stat in stats_list:\n",
    "        user_dict['stats'][stat.find_element_by_class_name('title').text] = int(stat.find_element_by_class_name('stat').text.replace(',', ''))\n",
    "        \n",
    "    user_data.append(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(user_checkpointer()[1], 'w') as wtr:\n",
    "    json.dump(user_data, wtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_elem.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
